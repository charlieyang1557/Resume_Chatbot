{"id": "resume#contact", "source": "resume", "section": "Contact", "date_range": "", "skills": ["Contact"], "text": "Name: Yutian (Charlie) Yang. Phone: 501-368-9640. Email: charlieyang990314@gmail.com. Website: charlieyang1557.github.io/aboutme/. LinkedIn: linkedin.com/in/yutianyang."}
{"id": "resume#education_ms", "source": "resume", "section": "Education > UC Davis (MS Statistics)", "date_range": "09/2021–06/2023", "skills": ["Statistics", "Algorithms", "Econometrics", "Optimization", "ML", "Time Series", "Probability"], "text": "University of California, Davis — Master of Science in Statistics. Relevant coursework: Advanced Statistical Computing, Algorithm Design & Analysis, Econometrics, Optimization of Big Data Analytics, Statistical Machine Learning I, Methods of Machine Learning, Time Series Analysis, Probability Theory."}
{"id": "resume#education_bs", "source": "resume", "section": "Education > UC Davis (BS Statistics & Economics)", "date_range": "09/2017–06/2021", "skills": ["Statistics", "Economics"], "text": "University of California, Davis — Bachelor of Science in Statistics and Economics."}
{"id": "resume#skills", "source": "resume", "section": "Skills & Tools", "date_range": "", "skills": ["SQL", "Python", "R", "Scikit-learn", "TensorFlow", "Random Forests", "SVM", "CNN", "Time Series", "BigQuery", "DBT", "AWS", "GCP", "ETL", "Schema Design", "Tableau", "Power BI", "Looker", "Sigma", "Google Analytics"], "text": "Programming: SQL, Python, R. Machine Learning: Scikit-learn, TensorFlow, Random Forests, SVM, CNN, Time Series. Data Engineering: BigQuery, DBT, AWS, GCP, ETL, Schema Design. BI & Analytics: Tableau, Power BI, Looker, Sigma, Google Analytics."}
{"id": "resume#exp_onshape_overview", "source": "resume", "section": "Experience > PTC Onshape (Data Science Intern, R&D Strategy)", "date_range": "06/2025–08/2025", "skills": ["Anomaly Detection", "Prophet", "Isolation Forest", "Merlion", "LSTM-AE", "AWS Bedrock", "Titan Embeddings", "Claude 3.5 Sonnet", "NPS Analysis", "Keyword Analysis", "RAG Content Coverage", "Looker", "Slack Reporting"], "text": "Built and evaluated unsupervised anomaly detection for API telemetry (Prophet + Isolation Forest, Merlion, LSTM-AE). Deployed a Prophet-based pipeline for performance, interpretability, and ease of deployment. Used AWS Bedrock Titan Embeddings and Claude 3.5 Sonnet for clustering, naming, and sentiment analysis of NPS feedback; extracted key themes from unstructured text. Performed keyword analysis on AI Advisor open-field queries to measure reference URL coverage and content gaps. Developed Looker dashboards to track anomaly alerts and AI insights; automated Slack reporting to reduce manual monitoring."}
{"id": "resume#exp_pinecone_overview", "source": "resume", "section": "Experience > Pinecone (Data Science Intern)", "date_range": "06/2024–08/2024", "skills": ["SQL", "Sigma", "RLS", "BigQuery", "DBT", "Churn Analysis", "Random Forest", "Dashboards", "Documentation", "Notion"], "text": "Designed and built Book of Business and Account 360 dashboards with SQL and Sigma, improving sales operations by ~15%; implemented Row-Level Security for tailored views and documented processes in Notion, reducing onboarding time by ~30%. Developed a 'dim_assistants' schema in BigQuery/DBT and a Pinecone Assistant dashboard enabling comprehensive metric tracking, supporting cross-team collaboration and a ~25% increase in product insights. Conducted churn analysis (Python, Random Forest), identified 5 key metrics, and set alerts—reducing churn by ~10%; improved data collection projected to boost accuracy by ~20%."}
{"id": "resume#exp_allschool", "source": "resume", "section": "Experience > Allschool (Data Analyst Intern, Growth & BI)", "date_range": "06/2022–08/2022", "skills": ["Google Analytics", "A/B Testing", "Segmentation", "SQL", "BI", "Web Scraping", "Selenium", "Dashboarding", "Looker Studio"], "text": "Enhanced impression targeting via A/B testing and segmentation across regions/platforms using Google Analytics. Analyzed multi-channel behavior, reducing project budget by ~15% and increasing DAU using SQL and BI. Built a real-time Python/Selenium scraper accelerating class selection by ~50%. Created key metrics dashboard (active users, traffic, revenue) in Looker Studio to improve visibility and decision-making."}
{"id": "resume#exp_ra_ucd", "source": "resume", "section": "Experience > UC Davis Economics (Research Assistant)", "date_range": "07/2020–09/2020", "skills": ["GLM", "Logistic Regression", "Bootstrapping", "Regularization", "Lasso", "Behavioral Analysis"], "text": "Analyzed procrastination and present-bias using GLM and Logistic Regression in a study with Prof. Anujit Chakraborty. Boosted reliability with bootstrapping to ~20,000 samples. Addressed multicollinearity and improved predictive accuracy using Lasso regularization. Outlined industry implications for tech product design to enhance user satisfaction, retention, and success."}
{"id": "resume#proj_mushroom", "source": "resume", "section": "Projects > Mushroom Classification (STA-221)", "date_range": "", "skills": ["Random Forest", "Kernel SVM", "CNN", "Grid Search", "Transfer Learning", "ResNet50"], "text": "Team project building ML/DL models (Random Forest, Kernel SVM, CNN) to classify mushrooms as edible vs poisonous. Applied grid search for hyperparameter tuning and transfer learning with pre-trained ResNet50 to improve efficiency and accuracy. Proposed enhancements via alternative pretrained backbones and architectural adjustments.", "url": "https://github.com/charlieyang1557/STA-221-Mushroom-Classification"}
{"id": "website#about", "source": "website", "section": "About Me (placeholder)", "date_range": "", "skills": [], "text": "PLACEHOLDER extracted from personal website. Replace this with scraped sections like About, Projects, and Experience.", "url": "https://charlieyang1557.github.io/aboutme/"}
{"id": "linkedin#summary", "source": "linkedin", "section": "Summary (placeholder)", "date_range": "", "skills": [], "text": "PLACEHOLDER extracted from LinkedIn Summary/Experience. Replace with LinkedIn exported text to enrich context.", "url": "https://www.linkedin.com/in/yutianyang/"}
{"id": "website#about_c1", "source": "website", "section": "About Me", "date_range": "", "skills": ["AWS", "Anomaly Detection", "BigQuery", "DBT", "Dashboards", "GCP", "Isolation Forest", "LSTM", "Looker", "NPS", "Power BI", "Prophet", "Python", "R", "SQL", "Scikit-learn", "Tableau", "TensorFlow", "Time Series"], "text": "I'm Yutian Yang, a passionate data scientist and analytics engineer with a strong background in machine learning, statistical analysis, and data engineering. I specialize in building end-to-end ML pipelines, automating analytics workflows, and communicating findings with stakeholders across product, growth, and research teams. My technical expertise spans Python, SQL, R, and various ML frameworks including Scikit-learn, TensorFlow, and time series analysis tools. I have hands-on experience with cloud platforms like AWS and GCP, data engineering tools like BigQuery and DBT, and visualization platforms including Tableau, Power BI, and Looker. In my recent role at PTC Onshape, I built unsupervised anomaly detection systems for API telemetry using Prophet, Isolation Forest, and LSTM-AE models. I also developed AI-powered NPS analysis pipelines using AWS Bedrock and Claude 3. 5 Sonnet for sentiment analysis and theme extraction. At Pinecone, I designed and built comprehensive dashboards that improved sales operations by 15% and developed churn analysis models using Random Forest that reduced churn by 10%.", "url": "https://charlieyang1557.github.io/aboutme/"}
{"id": "website#about_c2", "source": "website", "section": "About Me", "date_range": "", "skills": ["R"], "text": "improved sales operations by 15% and developed churn analysis models using Random Forest that reduced churn by 10%. I'm passionate about turning complex data into actionable insights that drive business decisions. I hold a Master's degree in Statistics from UC Davis and enjoy working on projects that combine statistical rigor with practical business applications. When I'm not coding, I love exploring new ML techniques and contributing to open-source projects.", "url": "https://charlieyang1557.github.io/aboutme/"}
{"id": "website#projects_c1", "source": "website", "section": "Projects", "date_range": "", "skills": ["AWS", "Anomaly Detection", "BigQuery", "Dashboards", "Isolation Forest", "LSTM", "Merlion", "Prophet", "Python", "R", "SQL", "Scikit-learn", "Sigma", "Time Series"], "text": "## Machine Learning Projects ### Real-time Anomaly Detection System Built a comprehensive anomaly detection pipeline for API telemetry data at PTC Onshape. Implemented multiple algorithms including Prophet for time series forecasting, Isolation Forest for outlier detection, and LSTM-AE for deep learning-based anomaly detection. The system achieved 95% accuracy in detecting API performance anomalies and reduced manual monitoring by 80%. Technologies: Python, Prophet, Isolation Forest, Merlion, LSTM, AWS Bedrock, Claude 3. 5 Sonnet ### Customer Churn Prediction Model Developed a Random Forest-based churn prediction model at Pinecone that identified key customer behavior patterns. The model analyzed 15+ customer metrics and achieved 87% accuracy in predicting churn risk. Implemented automated alerts and dashboard visualizations that helped reduce customer churn by 10%. Technologies: Python, Scikit-learn, Random Forest, SQL, BigQuery, Sigma ### Mushroom Classification Project Team project building ML/DL models to classify mushrooms as edible vs poisonous using multiple approaches. Implemented Random Forest, Kernel SVM, and CNN models with grid search hyperparameter tuning.", "url": "https://charlieyang1557.github.io/aboutme/"}
{"id": "website#projects_c2", "source": "website", "section": "Projects", "date_range": "", "skills": ["Python", "R", "Scikit-learn", "TensorFlow"], "text": "multiple approaches. Implemented Random Forest, Kernel SVM, and CNN models with grid search hyperparameter tuning. Applied transfer learning with pre-trained ResNet50 to improve efficiency and accuracy. Technologies: Python, Scikit-learn, TensorFlow, CNN, ResNet50, Grid Search ### Behavioral Analysis Research Conducted research on procrastination and present-bias using GLM and Logistic Regression at UC Davis. Analyzed 20,000+ samples using bootstrapping techniques and addressed multicollinearity using Lasso regularization. Results provided insights for tech product design to enhance user satisfaction and retention. Technologies: R, GLM, Logistic Regression, Bootstrapping, Lasso Regularization ## Data Engineering Projects ### Automated ETL Pipeline Built end-to-end ETL pipelines processing 10TB+ of daily data using Python, Airflow, and cloud platforms. Implemented data quality checks, automated monitoring, and error handling that reduced manual intervention by 90%.", "url": "https://charlieyang1557.github.io/aboutme/"}
{"id": "website#projects_c3", "source": "website", "section": "Projects", "date_range": "", "skills": ["AWS", "BigQuery", "DBT", "Dashboards", "GCP", "Google Analytics", "Looker", "Power BI", "Python", "R", "SQL", "Sigma", "Tableau"], "text": "Implemented data quality checks, automated monitoring, and error handling that reduced manual intervention by 90%. Technologies: Python, Apache Airflow, AWS, GCP, BigQuery, DBT ### Real-time Dashboard System Created comprehensive business intelligence dashboards using Looker and Tableau that provided real-time insights to stakeholders. Implemented Row-Level Security for tailored views and automated reporting that reduced manual reporting time by 70%. Technologies: SQL, Looker, Tableau, Power BI, Sigma, Google Analytics", "url": "https://charlieyang1557.github.io/aboutme/"}
